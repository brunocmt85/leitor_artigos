title,title_pt,author,abstract,abstract_pt
Empirical Analysis of Artificial Immune System Algorithms for Aging Related Bug Prediction,Análise empírica de algoritmos de sistema imunológico artificial para previsão de bugs relacionados ao envelhecimento,"Khanna, Megha and Aggarwal, Mehak and Singhal, Naman","The complex nature of human immunology algorithms has motivated the research community to explore their practical applications in various other fields. As a result, Artificial Immune Systems (AISs) is one such class of algorithms that has found its way into software quality predictive modeling. In this paper, we evaluate AIS algorithms for developing Aging-Related Bug (ARB) prediction models. Software Aging, the gradual degradation and resource exhaustion in software systems, is said to be caused by ARBs, which may or may not be identified during software testing. Therefore, predicting ARBs before software release can help software managers in reducing their impact. This paper presents an empirical study that statistically analyzes the effectiveness of AIS classifiers for ARB prediction on five open-source software datasets. In order to account for the imbalanced nature of the investigated datasets, we used resampling and cost-sensitive classifiers. The results of the study indicate the effectiveness of AIS algorithms for developing ARB prediction models.","A natureza complexa dos algoritmos de imunologia humana motivou a comunidade científica a explorar as suas aplicações práticas em vários outros campos. Como resultado, os Sistemas Imunológicos Artificiais (AISs) são uma dessas classes de algoritmos que encontraram seu caminho na modelagem preditiva de qualidade de software. Neste artigo, avaliamos algoritmos AIS para o desenvolvimento de modelos de predição de Bugs Relacionados ao Envelhecimento (ARB). Diz-se que o envelhecimento do software, a degradação gradual e o esgotamento de recursos em sistemas de software, é causado por ARBs, que podem ou não ser identificados durante os testes de software. Portanto, prever ARBs antes do lançamento do software pode ajudar os gerentes de software a reduzir seu impacto. Este artigo apresenta um estudo empírico que analisa estatisticamente a eficácia dos classificadores AIS para previsão de ARB em cinco conjuntos de dados de software de código aberto. Para dar conta da natureza desequilibrada dos conjuntos de dados investigados, utilizamos reamostragem e classificadores sensíveis ao custo. Os resultados do estudo indicam a eficácia dos algoritmos AIS no desenvolvimento de modelos de predição ARB."
Hybrid Software Obsolescence Evaluation Model Based on PCA-SVM-GridSearchCV,Modelo de avaliação de obsolescência de software híbrido baseado em PCA-SVM-GridSearchCV,"Shuai, Yong and Zheng, Yujie and Huang, Hao","For the sake of establishing an accurate software obsolescence evaluation model scientifically and systematically, this paper points out the mechanism and definition of software obsolescence. By the way of analyzing software obsolescence mechanism, 20 software obsolescence correlative characteristic parameters are collected, preprocessed and scaled by RobustScaler, and then PCA is used to extract feature and reduce dimension, eliminate the noise value in the feature data and select important software obsolete feature data. Use GridSearchCV class to optimize support vector machine parameters and build SVM classification model, use confusion matrix accuracy to evaluate the machine model, finally the example verify the evaluation model to be believable and effective.","Com o objetivo de estabelecer um modelo preciso de avaliação de obsolescência de software de forma científica e sistemática, este artigo aponta o mecanismo e a definição de obsolescência de software. A propósito da análise do mecanismo de obsolescência de software, 20 parâmetros de características correlativas de obsolescência de software são coletados, pré-processados ​​​​e dimensionados pelo RobustScaler e, em seguida, o PCA é usado para extrair recursos e reduzir dimensões, eliminar o valor de ruído nos dados de recursos e selecionar dados importantes de recursos obsoletos de software. Use a classe GridSearchCV para otimizar os parâmetros da máquina de vetores de suporte e construir o modelo de classificação SVM, use a precisão da matriz de confusão para avaliar o modelo da máquina e, finalmente, o exemplo verifica se o modelo de avaliação é confiável e eficaz."
Improving Statistical Approach for Memory Leak Detection Using Machine Learning,Melhorando a abordagem estatística para detecção de vazamento de memória usando aprendizado de máquina,"Sor, Vladimir and Oü, Plumbr and Treier, Tarvo and Srirama, Satish Narayana","Memory leaks are major problems in all kinds of applications, depleting their performance, even if they run on platforms with automatic memory management, such as Java Virtual Machine. In addition, memory leaks contribute to software aging, increasing the complexity of software maintenance. So far memory leak detection was considered to be a part of development process, rather than part of software maintenance. To detect slow memory leaks as a part of quality assurance process or in production environments statistical approach for memory leak detection was implemented and deployed in a commercial tool called Plumbr. It showed promising results in terms of leak detection precision and recall, however, even better detection quality was desired. To achieve this improvement goal, classification algorithms were applied to the statistical data, which was gathered from customer environments where Plumbr was deployed. This paper presents the challenges which had to be solved, method that was used to generate features for supervised learning and the results of the corresponding experiments.","Vazamentos de memória são grandes problemas em todos os tipos de aplicações, esgotando seu desempenho, mesmo que sejam executadas em plataformas com gerenciamento automático de memória, como Java Virtual Machine. Além disso, os vazamentos de memória contribuem para o envelhecimento do software, aumentando a complexidade da manutenção do software. Até agora, a detecção de vazamento de memória era considerada parte do processo de desenvolvimento, e não da manutenção do software. Para detectar vazamentos lentos de memória como parte do processo de garantia de qualidade ou em ambientes de produção, uma abordagem estatística para detecção de vazamento de memória foi implementada e implantada em uma ferramenta comercial chamada Plumbr. Ele mostrou resultados promissores em termos de precisão e recall de detecção de vazamentos, no entanto, era desejada uma qualidade de detecção ainda melhor. Para atingir esse objetivo de melhoria, foram aplicados algoritmos de classificação aos dados estatísticos, coletados nos ambientes dos clientes onde o Plumbr foi implantado. Este artigo apresenta os desafios que tiveram que ser resolvidos, o método utilizado para gerar funcionalidades para aprendizagem supervisionada e os resultados dos experimentos correspondentes."
Aging-Related Bugs Prediction Via Convolutional Neural Network,Previsão de bugs relacionados ao envelhecimento por meio de rede neural convolucional,"Liu, Qinchen and Xiang, Jianwen and Xu, Bin and Zhao, Dongdong and Hu, Wenhua and Wang, Jian","Software aging refers to the phenomenon of system performance degradation or system crash in long-term running systems, which is mainly caused by Aging-Related Bugs (ARBs). To predict Aging-Related Bugs, previous studies usually focused on manually designing features, which extracted from the programs, and utilized different machine learning algorithms to detect those buggy codes. However, these traditional features often failed to distinguish programs' semantic differences.To explore deeply programs' semantics and make full use of these information, in this paper, we proposed a method, which based on deep learning method to automatically learn programs' semantic features of source codes. Specifically, we utilized Convolutional Neural Network (CNN) to automatically generate more distinguished features which based on the Abstract Syntax Trees (ASTs) of programs. Meanwhile, we combined these features with conventional aging-related metrics for more accurate ARB prediction. Finally, we evaluated our model on Linux and MySQL datasets, the experiment results showed that our approach was better than the baselines. The improvement can be achieved up to 6.9% on Linux, and 24.1% on MySQL in terms of balance, compared to traditional Naive Bayes method. And compared to Naive Bayes with logarithmic transformation, the improvement is 1% and 4.7% respectively.","O envelhecimento do software refere-se ao fenômeno de degradação do desempenho do sistema ou falha do sistema em sistemas em execução de longo prazo, que é causado principalmente por Bugs Relacionados ao Envelhecimento (ARBs). Para prever bugs relacionados ao envelhecimento, estudos anteriores geralmente se concentravam no design manual de recursos, extraídos dos programas, e utilizavam diferentes algoritmos de aprendizado de máquina para detectar esses códigos de bugs. No entanto, esses recursos tradicionais muitas vezes falham em distinguir as diferenças semânticas dos programas. Para explorar profundamente a semântica dos programas e fazer uso completo dessas informações, neste artigo, propusemos um método baseado no método de aprendizagem profunda para aprender automaticamente os recursos semânticos dos códigos-fonte dos programas. Especificamente, utilizamos Rede Neural Convolucional (CNN) para gerar automaticamente recursos mais distintos baseados nas Árvores de Sintaxe Abstrata (ASTs) de programas. Enquanto isso, combinamos esses recursos com métricas convencionais relacionadas ao envelhecimento para uma previsão ARB mais precisa. Finalmente, avaliamos nosso modelo em conjuntos de dados Linux e MySQL, os resultados do experimento mostraram que nossa abordagem era melhor do que as linhas de base. A melhoria pode ser alcançada em até 6,9% no Linux e 24,1% no MySQL em termos de equilíbrio, em comparação com o método tradicional Naive Bayes. E em comparação com Naive Bayes com transformação logarítmica, a melhoria é de 1% e 4,7% respectivamente."
On the Use of ADM to Contextualize Data on Legacy Source Code for Software Modernization,Sobre o uso de ADM para contextualizar dados em código-fonte legado para modernização de software,"Perez-Castillo, Ricardo and de Guzman, Ignacio Garcia-Rodriguez and Avila-Garcia, Orlando and Piattini, Mario","Legacy systems are usually made of two kind of artifacts: source code and databases. Typically, the maintenance of those systems is carried out through re-engineering processes. Although both artifacts can be independently maintained, for a more effective re-engineering of the whole system both should be analyzed and evolved jointly. This is mainly due to the fact that the knowledge expected to be extracted by analyzing both kind of artifacts at the same time is greater and richer than the one recovered by just looking at the system partly, and thus ROI and lifespan of the system are expected to improve. This paper proposes the data contextualization for recovering code-to-data linkages in legacy systems. This technique is framed in the ADM (architecture driven modernization) approach to modernization of legacy systems, considering all involved artifacts as models. This paper also presents a tool to support that technique throughout a real-life case study.","Os sistemas legados geralmente são compostos por dois tipos de artefatos: código-fonte e bancos de dados. Normalmente, a manutenção desses sistemas é realizada através de processos de reengenharia. Embora ambos os artefactos possam ser mantidos de forma independente, para uma reengenharia mais eficaz de todo o sistema, ambos devem ser analisados ​​e evoluídos em conjunto. Isto se deve principalmente ao fato de que o conhecimento que se espera extrair pela análise de ambos os tipos de artefatos ao mesmo tempo é maior e mais rico do que aquele recuperado apenas olhando parcialmente para o sistema e, portanto, espera-se que o ROI e a vida útil do sistema melhorem. Este artigo propõe a contextualização de dados para recuperar ligações código-dados em sistemas legados. Esta técnica está enquadrada na abordagem ADM (modernização dirigida por arquitetura) para modernização de sistemas legados, considerando todos os artefatos envolvidos como modelos. Este artigo também apresenta uma ferramenta para apoiar essa técnica em um estudo de caso real."
Requirements for an effective architecture recovery framework,Requisitos para uma estrutura eficaz de recuperação de arquitetura,"Mendon\c{c}a, Nabor C. and Kramer, Jeff",,#VALUE!
Taming compiler fuzzers,Domando fuzzers do compilador,"Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John","Aggressive random testing tools (""fuzzers"") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.","Ferramentas agressivas de testes aleatórios (""fuzzers"") são impressionantemente eficazes na localização de bugs do compilador. Por exemplo, um único gerador de casos de teste resultou em mais de 1.700 bugs relatados para um único mecanismo JavaScript. No entanto, o uso de fuzzers pode ser frustrante: eles encontram bugs indiscriminadamente e repetidamente que podem não ser graves o suficiente para serem corrigidos imediatamente. Atualmente, os usuários filtram casos de teste indesejáveis ​​usando métodos ad hoc, como proibir recursos problemáticos em testes e obter resultados de testes. Este artigo formula e aborda o problema de domesticação do fuzzer: dado um número potencialmente grande de casos de teste aleatórios que desencadeiam falhas, ordene-os de forma que casos de teste diversos e interessantes sejam altamente classificados. Nossa avaliação mostra nossa capacidade de resolver o problema de domesticação do fuzzer para 3.799 casos de teste que dispararam 46 bugs em um compilador C e 2.603 casos de teste que desencadearam 28 bugs em um mecanismo JavaScript."
Light analysis of complex systems,Análise leve de sistemas complexos,"Marchiori, Massimo",,#VALUE!
Reengineering of configurations based on mathematical concept analysis,Reengenharia de configurações com base na análise de conceitos matemáticos,"Snelting, Gregor",,#VALUE!
NSPW '23: Proceedings of the 2023 New Security Paradigms Workshop,NSPW '23: Procedimentos do Workshop de Novos Paradigmas de Segurança de 2023,,,#VALUE!
SDN Controllers: A Comprehensive Analysis and Performance Evaluation Study,Controladores SDN: um estudo abrangente de análise e avaliação de desempenho,"Zhu, Liehuang and Karim, Md M. and Sharif, Kashif and Xu, Chang and Li, Fan and Du, Xiaojiang and Guizani, Mohsen","Software-defined networks offer flexible and intelligent network operations by splitting a traditional network into a centralized control plane and a programmable data plane. The controller in the control plane is the fundamental element used to manage all operations of the data plane. Hence, the performance and capabilities of the controller itself are essential in achieving optimal performance. Furthermore, the tools used to benchmark their performance must be accurate and useful in measuring different evaluation parameters. There are dozens of controller proposals for general and specialized networks in the literature. However, there is a very limited comprehensive quantitative analysis for them. In this article, we present a comprehensive qualitative comparison of different SDN controllers, along with a quantitative analysis of their performance in different network scenarios. We categorize and classify 34 controllers and present a qualitative comparison. We also present a comparative analysis of controllers for specialized networks such as the Internet of Things, blockchain networks, vehicular networks, and wireless sensor networks. We also discuss in-depth capabilities of benchmarking tools and provide a comparative analysis of their capabilities. This work uses three benchmarking tools to compare 9 controllers and presents a detailed analysis of their performance, along with discussion on performance of specialized network controllers.","As redes definidas por software oferecem operações de rede flexíveis e inteligentes, dividindo uma rede tradicional em um plano de controle centralizado e um plano de dados programável. O controlador no plano de controle é o elemento fundamental usado para gerenciar todas as operações do plano de dados. Conseqüentemente, o desempenho e as capacidades do próprio controlador são essenciais para alcançar o desempenho ideal. Além disso, as ferramentas utilizadas para avaliar o seu desempenho devem ser precisas e úteis na medição de diferentes parâmetros de avaliação. Existem dezenas de propostas de controladores para redes gerais e especializadas na literatura. No entanto, há uma análise quantitativa abrangente muito limitada para eles. Neste artigo, apresentamos uma comparação qualitativa abrangente de diferentes controladores SDN, juntamente com uma análise quantitativa de seu desempenho em diferentes cenários de rede. Categorizamos e classificamos 34 controladores e apresentamos uma comparação qualitativa. Apresentamos também uma análise comparativa de controladores para redes especializadas como Internet das Coisas, redes blockchain, redes veiculares e redes de sensores sem fio. Também discutimos capacidades aprofundadas das ferramentas de benchmarking e fornecemos uma análise comparativa de suas capacidades. Este trabalho utiliza três ferramentas de benchmarking para comparar 9 controladores e apresenta uma análise detalhada de seu desempenho, juntamente com uma discussão sobre o desempenho de controladores de rede especializados."
Trends in object-oriented software evolution: investigating network properties,Tendências na evolução do software orientado a objetos: investigando propriedades de rede,"Chatzigeorgiou, Alexander and Melas, George",The rise of social networks and the accompanying interest to study their evolution has stimulated a number of research efforts to analyze their growth patterns by means of network analysis. The inherent graph-like structure of object-oriented systems calls for the application of the corresponding methods and tools to analyze software evolution. In this paper we investigate network properties of two open-source systems and observe interesting phenomena regarding their growth. Relating the observed evolutionary trends to principles and laws of software design enables a high-level assessment of tendencies in the underlying design quality.,A ascensão das redes sociais e o consequente interesse em estudar a sua evolução estimulou uma série de esforços de investigação para analisar os seus padrões de crescimento através da análise de redes. A estrutura gráfica inerente aos sistemas orientados a objetos exige a aplicação dos métodos e ferramentas correspondentes para analisar a evolução do software. Neste artigo investigamos propriedades de rede de dois sistemas de código aberto e observamos fenômenos interessantes em relação ao seu crescimento. Relacionar as tendências evolutivas observadas aos princípios e leis do design de software permite uma avaliação de alto nível das tendências na qualidade do design subjacente.
Towards dependable clients: improving the reliability and availability of the browsers,Rumo a clientes confiáveis: melhorando a confiabilidade e a disponibilidade dos navegadores,"Rudafshani, Masoomeh and Ward, Paul A. S.","According to autonomic computing vision, system dependability can be improved by adding self-healing properties to make it capable of realizing failures and recovering from them automatically. Server-side self-healing is a well-established discipline and has resulted in substantial cost reductions for data centers. In contrast, self-healing on the client side has not been so well-studied.In this work, we present our approach for improving browser dependability. As desktop applications are being replaced by web applications, browsers are becoming the common application platform; therefore, it is critical for the browsers to be highly reliable and available. Our system is designed to achieve this goal by monitoring the browser components, analyzing the collected data using statistical techniques to predict failures, and taking actions to remove or reduce effects of errors if needed. This paper presents the overall draft of our solution for making the browser dependable, including the prototype architecture, its different components, and the related state of the art and future work.","De acordo com a visão da computação autônoma, a confiabilidade do sistema pode ser melhorada adicionando propriedades de autocura para torná-lo capaz de perceber falhas e se recuperar delas automaticamente. A autocorreção do lado do servidor é uma disciplina bem estabelecida e resultou em reduções substanciais de custos para data centers. Em contraste, a autocorreção no lado do cliente não foi tão bem estudada. Neste trabalho, apresentamos nossa abordagem para melhorar a confiabilidade do navegador. À medida que os aplicativos de desktop estão sendo substituídos por aplicativos da Web, os navegadores estão se tornando a plataforma de aplicativos comum; portanto, é fundamental que os navegadores sejam altamente confiáveis ​​e disponíveis. Nosso sistema foi projetado para atingir esse objetivo monitorando os componentes do navegador, analisando os dados coletados usando técnicas estatísticas para prever falhas e tomando ações para remover ou reduzir os efeitos dos erros, se necessário. Este artigo apresenta o esboço geral da nossa solução para tornar o navegador confiável, incluindo a arquitetura do protótipo, seus diferentes componentes e o estado da arte relacionado e trabalhos futuros."
A survey of online failure prediction methods,Uma pesquisa sobre métodos de previsão de falhas on-line,"Salfner, Felix and Lenk, Maren and Malek, Miroslaw","With the ever-growing complexity and dynamicity of computer systems, proactive fault management is an effective approach to enhancing availability. Online failure prediction is the key to such techniques. In contrast to classical reliability methods, online failure prediction is based on runtime monitoring and a variety of models and methods that use the current state of a system and, frequently, the past experience as well. This survey describes these methods. To capture the wide spectrum of approaches concerning this area, a taxonomy has been developed, whose different approaches are explained and major concepts are described in detail.","Com a complexidade e a dinamicidade cada vez maiores dos sistemas computacionais, o gerenciamento proativo de falhas é uma abordagem eficaz para aumentar a disponibilidade. A previsão de falhas online é a chave para tais técnicas. Em contraste com os métodos clássicos de confiabilidade, a previsão de falhas on-line é baseada no monitoramento do tempo de execução e em uma variedade de modelos e métodos que utilizam o estado atual de um sistema e, frequentemente, também a experiência passada. Esta pesquisa descreve esses métodos. Para captar o amplo espectro de abordagens relativas a esta área, foi desenvolvida uma taxonomia, cujas diferentes abordagens são explicadas e os principais conceitos são descritos em detalhe."
EXA2PRO programming environment: architecture and applications,Ambiente de programação EXA2PRO: arquitetura e aplicações,"Soudris, Dimitrios and Papadopoulos, Lazaros and Kessler, Christoph W. and Kehagias, Dionysios D. and Papadopoulos, Athanasios and Seferlis, Panos and Chatzigeorgiou, Alexander and Ampatzoglou, Apostolos and Thibault, Samuel and Namyst, Raymond and Pleiter, Dirk and Gaydadjiev, Georgi and Becker, Tobias and Haefele, Matthieu","The EXA2PRO programming environment will integrate a set of tools and methodologies that will allow to systematically address many exascale computing challenges, including performance, performance portability, programmability, abstraction and reusability, fault tolerance and technical debt. The EXA2PRO tool-chain will enable the efficient deployment of applications in exascale computing systems, by integrating high-level software abstractions that offer performance portability and efficient exploitation of exascale systems' heterogeneity, tools for efficient memory management, optimizations based on trade-offs between various metrics and fault-tolerance support. Hence, by addressing various aspects of productivity challenges, EXA2PRO is expected to have significant impact in the transition to exascale computing, as well as impact from the perspective of applications. The evaluation will be based on 4 applications from 4 different domains that will be deployed in JUELICH supercomputing center. The EXA2PRO will generate exploitable results in the form of a tool-chain that support diverse exascale heterogeneous supercomputing centers and concrete improvements in various exascale computing challenges.","O ambiente de programação EXA2PRO integrará um conjunto de ferramentas e metodologias que permitirão abordar sistematicamente muitos desafios de computação em exaescala, incluindo desempenho, portabilidade de desempenho, programabilidade, abstração e reutilização, tolerância a falhas e dívida técnica. A cadeia de ferramentas EXA2PRO permitirá a implantação eficiente de aplicações em sistemas de computação em exaescala, integrando abstrações de software de alto nível que oferecem portabilidade de desempenho e exploração eficiente da heterogeneidade dos sistemas em exaescala, ferramentas para gerenciamento eficiente de memória, otimizações baseadas em compensações entre várias métricas e suporte à tolerância a falhas. Assim, ao abordar vários aspectos dos desafios de produtividade, espera-se que EXA2PRO tenha um impacto significativo na transição para a computação em exaescala, bem como um impacto na perspectiva das aplicações. A avaliação será baseada em 4 aplicações de 4 domínios diferentes que serão implantadas no centro de supercomputação JUELICH. O EXA2PRO gerará resultados exploráveis ​​na forma de uma cadeia de ferramentas que suporta diversos centros de supercomputação heterogêneos em exaescala e melhorias concretas em vários desafios de computação em exaescala."
SH\~{o}WA: A Self-Healing Framework for Web-Based Applications,SH\~{o}WA: uma estrutura de autocorreção para aplicativos baseados na Web,"Magalh\~{a}es, Jo\~{a}o Paulo and Silva, Luis Moura","The complexity of systems is considered an obstacle to the progress of the IT industry. Autonomic computing is presented as the alternative to cope with the growing complexity. It is a holistic approach, in which the systems are able to configure, heal, optimize, and protect by themselves. Web-based applications are an example of systems where the complexity is high. The number of components, their interoperability, and workload variations are factors that may lead to performance failures or unavailability scenarios. The occurrence of these scenarios affects the revenue and reputation of businesses that rely on these types of applications.In this article, we present a self-healing framework for Web-based applications (SH\~{o}WA). SH\~{o}WA is composed by several modules, which monitor the application, analyze the data to detect and pinpoint anomalies, and execute recovery actions autonomously. The monitoring is done by a small aspect-oriented programming agent. This agent does not require changes to the application source code and includes adaptive and selective algorithms to regulate the level of monitoring. The anomalies are detected and pinpointed by means of statistical correlation. The data analysis detects changes in the server response time and analyzes if those changes are correlated with the workload or are due to a performance anomaly. In the presence of performance anomalies, the data analysis pinpoints the anomaly. Upon the pinpointing of anomalies, SH\~{o}WA executes a recovery procedure. We also present a study about the detection and localization of anomalies, the accuracy of the data analysis, and the performance impact induced by SH\~{o}WA. Two benchmarking applications, exercised through dynamic workloads, and different types of anomaly were considered in the study. The results reveal that (1) the capacity of SH\~{o}WA to detect and pinpoint anomalies while the number of end users affected is low; (2) SH\~{o}WA was able to detect anomalies without raising any false alarm; and (3) SH\~{o}WA does not induce a significant performance overhead (throughput was affected in less than 1%, and the response time delay was no more than 2 milliseconds).","A complexidade dos sistemas é considerada um obstáculo ao progresso da indústria de TI. A computação autônoma se apresenta como alternativa para lidar com a crescente complexidade. É uma abordagem holística, na qual os sistemas são capazes de configurar, curar, otimizar e proteger por si próprios. Os aplicativos baseados na Web são um exemplo de sistemas onde a complexidade é alta. A quantidade de componentes, sua interoperabilidade e variações de carga de trabalho são fatores que podem levar a falhas de desempenho ou cenários de indisponibilidade. A ocorrência desses cenários afeta a receita e a reputação das empresas que dependem desses tipos de aplicativos. Neste artigo, apresentamos uma estrutura de autocorreção para aplicativos baseados na Web (SH\~{o}WA). O SH\~{o}WA é composto por diversos módulos, que monitoram a aplicação, analisam os dados para detectar e identificar anomalias e executam ações de recuperação de forma autônoma. O monitoramento é feito por um pequeno agente de programação orientado a aspectos. Este agente não requer alterações no código-fonte da aplicação e inclui algoritmos adaptativos e seletivos para regular o nível de monitoramento. As anomalias são detectadas e identificadas por meio de correlação estatística. A análise de dados detecta alterações no tempo de resposta do servidor e analisa se essas alterações estão correlacionadas com a carga de trabalho ou são devidas a uma anomalia de desempenho. Na presença de anomalias de desempenho, a análise de dados identifica a anomalia. Ao identificar anomalias, o SH\~{o}WA executa um procedimento de recuperação. Apresentamos também um estudo sobre a detecção e localização de anomalias, a precisão da análise de dados e o impacto no desempenho induzido pelo SH\~{o}WA. Duas aplicações de benchmarking, exercidas por meio de cargas de trabalho dinâmicas, e diferentes tipos de anomalia foram consideradas no estudo. Os resultados revelam que (1) a capacidade do SH\~{o}WA para detectar e identificar anomalias enquanto o número de utilizadores finais afectados é baixo; (2) SH\~{o}WA foi capaz de detectar anomalias sem gerar qualquer alarme falso; e (3) SH\~{o}WA não induz uma sobrecarga significativa de desempenho (a taxa de transferência foi afetada em menos de 1% e o atraso no tempo de resposta não foi superior a 2 milissegundos)."
MemRed: towards reliable web applications,MemRed: rumo a aplicações web confiáveis,"Rudafshani, Masoomeh and Ward, Paul A. S. and Wong, Bernard","Current approaches for improving the reliability of web services focus on server side data collection and analysis to detect errors and prevent failures. However, significant portions of modern web applications are executed on the client browser with the server only acting as a data store. These applications are mostly developed using Javascript, which presents a challenge for developing reliable web applications due to a current lack of tools for debugging Javascript applications. In addition, these applications use AJAX to communicate with the server asynchronously; therefore they remain on the same page during their lifetime that can lead to runaway memory usage from even minor memory leaks. In this paper, we introduce MemRed, a system that improves the reliability of the client side of web applications. It achieves this goal by taking advantage of browser APIs to monitor web applications. It analyzes the collected data to detect excessive memory utilization and applies recovery action to hide failures from end users, if needed. Our prototype is implemented as an extension for the Chrome browser. The evaluation shows the effectiveness of recovery actions in lowering memory usage of web applications.","As abordagens atuais para melhorar a confiabilidade dos serviços web concentram-se na coleta e análise de dados no servidor para detectar erros e prevenir falhas. No entanto, partes significativas das aplicações web modernas são executadas no navegador do cliente, com o servidor atuando apenas como armazenamento de dados. Essas aplicações são desenvolvidas principalmente em Javascript, o que representa um desafio para o desenvolvimento de aplicações web confiáveis ​​devido à atual falta de ferramentas para depuração de aplicações Javascript. Além disso, essas aplicações utilizam AJAX para se comunicarem com o servidor de forma assíncrona; portanto, eles permanecem na mesma página durante sua vida útil, o que pode levar ao uso descontrolado de memória, até mesmo por pequenos vazamentos de memória. Neste artigo, apresentamos o MemRed, um sistema que melhora a confiabilidade do lado cliente de aplicações web. Ele atinge esse objetivo aproveitando as APIs do navegador para monitorar aplicativos da web. Ele analisa os dados coletados para detectar utilização excessiva de memória e aplica ações de recuperação para ocultar falhas dos usuários finais, se necessário. Nosso protótipo é implementado como uma extensão para o navegador Chrome. A avaliação mostra a eficácia das ações de recuperação na redução do uso de memória de aplicações web."
SBES '22: Proceedings of the XXXVI Brazilian Symposium on Software Engineering,SBES '22: Anais do XXXVI Simpósio Brasileiro de Engenharia de Software,,,#VALUE!
ASE '16: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering,ASE '16: Anais da 31ª Conferência Internacional IEEE/ACM sobre Engenharia de Software Automatizada,,,#VALUE!
Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,Koli Calling '23: Procedimentos da 23ª Conferência Internacional Koli Calling sobre Pesquisa em Educação em Computação,,,#VALUE!
CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems,CHI EA '21: Resumos estendidos da Conferência CHI 2021 sobre Fatores Humanos em Sistemas Computacionais,,,#VALUE!
Tracking the software quality of Android applications along their evolution,Acompanhando a qualidade do software de aplicativos Android ao longo de sua evolução,"Hecht, Geoffrey and Benomar, Omar and Rouvoy, Romain and Moha, Naouel and Duchien, Laurence","Mobile apps are becoming complex software systems that must be developed quickly and evolve continuously to fit new user requirements and execution contexts. However, addressing these requirements may result in poor design choices, also known as antipatterns, which may incidentally degrade software quality and performance. Thus, the automatic detection and tracking of antipatterns in this apps are important activities in order to ease both maintenance and evolution. Moreover, they guide developers to refactor their applications and thus, to improve their quality. While antipatterns are well-known in object-oriented applications, their study in mobile applications is still in its infancy. In this paper, we analyze the evolution of mobile apps quality on 3,568 versions of 106 popular Android applications downloaded from the Google Play Store. For this purpose, we use a tooled approach, called Paprika, to identify 3 object-oriented and 4 Android-specific antipatterns from binaries of mobile apps, and to analyze their quality along evolutions.","Os aplicativos móveis estão se tornando sistemas de software complexos que devem ser desenvolvidos rapidamente e evoluir continuamente para atender aos novos requisitos dos usuários e contextos de execução. No entanto, atender a esses requisitos pode resultar em escolhas inadequadas de design, também conhecidas como antipadrões, que podem, incidentalmente, degradar a qualidade e o desempenho do software. Assim, a detecção e rastreamento automático de antipadrões nestas aplicações são atividades importantes para facilitar tanto a manutenção quanto a evolução. Além disso, orientam os desenvolvedores a refatorar suas aplicações e, assim, melhorar sua qualidade. Embora os antipadrões sejam bem conhecidos em aplicações orientadas a objetos, seu estudo em aplicações móveis ainda está em sua infância. Neste artigo, analisamos a evolução da qualidade dos aplicativos móveis em 3.568 versões de 106 aplicativos Android populares baixados da Google Play Store. Para tanto, utilizamos uma abordagem ferramental, chamada Paprika, para identificar 3 antipadrões orientados a objetos e 4 antipadrões específicos do Android a partir de binários de aplicativos móveis, e analisar sua qualidade ao longo da evolução."
Languages of Games and Play: A Systematic Mapping Study,Linguagens de jogos e brincadeiras: um estudo de mapeamento sistemático,"van Rozen, Riemer","Digital games are a powerful means for creating enticing, beautiful, educational, and often highly addictive interactive experiences that impact the lives of billions of players worldwide. We explore what informs the design and construction of good games to learn how to speed-up game development. In particular, we study to what extent languages, notations, patterns, and tools, can offer experts theoretical foundations, systematic techniques, and practical solutions they need to raise their productivity and improve the quality of games and play. Despite the growing number of publications on this topic there is currently no overview describing the state-of-the-art that relates research areas, goals, and applications. As a result, efforts and successes are often one-off, lessons learned go overlooked, language reuse remains minimal, and opportunities for collaboration and synergy are lost. We present a systematic map that identifies relevant publications and gives an overview of research areas and publication venues. In addition, we categorize research perspectives along common objectives, techniques, and approaches, illustrated by summaries of selected languages. Finally, we distill challenges and opportunities for future research and development.","Os jogos digitais são um meio poderoso para criar experiências interativas atraentes, bonitas, educativas e, muitas vezes, altamente viciantes, que impactam a vida de bilhões de jogadores em todo o mundo. Exploramos o que informa o design e a construção de bons jogos para aprender como acelerar o desenvolvimento de jogos. Em particular, estudamos até que ponto linguagens, notações, padrões e ferramentas podem oferecer aos especialistas fundamentos teóricos, técnicas sistemáticas e soluções práticas de que necessitam para aumentar a sua produtividade e melhorar a qualidade dos jogos e do jogo. Apesar do crescente número de publicações sobre este tema, atualmente não existe uma visão geral que descreva o estado da arte que relacione áreas de pesquisa, objetivos e aplicações. Como resultado, os esforços e os sucessos são muitas vezes pontuais, as lições aprendidas são ignoradas, a reutilização da língua permanece mínima e as oportunidades de colaboração e sinergia são perdidas. Apresentamos um mapa sistemático que identifica publicações relevantes e dá uma visão geral das áreas de pesquisa e locais de publicação. Além disso, categorizamos as perspectivas de pesquisa de acordo com objetivos, técnicas e abordagens comuns, ilustradas por resumos de idiomas selecionados. Finalmente, destilamos desafios e oportunidades para futuras pesquisas e desenvolvimento."
ICPE '24: Proceedings of the 15th ACM/SPEC International Conference on Performance Engineering,ICPE '24: Anais da 15ª Conferência Internacional ACM/SPEC sobre Engenharia de Desempenho,,"Years of planning have gone into preparing for ICPE 2024 in London, UK. For the first time in UK, the organization of ICPE has generated a great deal of excitement and expectation of productive interactions between the usual participants of ICPE conferences, the members of the various SPEC working groups, and a desire to increase the involvement of the local scientific community with ICPE.It is our pleasure to welcome you to the 15th ACM/SPEC International Conference on Performance Engineering (ICPE), hosted at South Kensington, London, UK, from May 7-11, 2024. ICPE is the leading international forum for presenting and discussing novel ideas, innovations, trends and experiences in the field of performance engineering.ICPE formed from merging the ACM Workshop on Software Performance (WOSP, since 1998) and the SPEC International Performance Engineering Workshop (SIPEW, since 2008). Despite the peculiar time we are all living in around the world, we are pleased to introduce an exciting program, which is the result of hard work by the authors, the program committee, and the conference organizers.","Anos de planejamento foram gastos na preparação para o ICPE 2024 em Londres, Reino Unido. Pela primeira vez no Reino Unido, a organização do ICPE gerou um grande entusiasmo e expectativa de interações produtivas entre os participantes habituais das conferências do ICPE, os membros dos vários grupos de trabalho do SPEC, e um desejo de aumentar o envolvimento da comunidade científica local com o ICPE. Temos o prazer de recebê-lo na 15ª Conferência Internacional ACM/SPEC sobre Engenharia de Desempenho (ICPE), sediada em South Kensington, Londres, Reino Unido, de 7 a 11 de maio de 2024. ICPE é o principal fórum internacional para apresentação e discussão de novas ideias, inovações, tendências e experiências na área de engenharia de desempenho. O ICPE foi formado a partir da fusão do ACM Workshop on Software Performance (WOSP, desde 1998) e do SPEC International Performance Engineering Workshop (SIPEW, desde 2008). Apesar do momento peculiar que vivemos em todo o mundo, temos o prazer de apresentar um programa emocionante, que é o resultado do trabalho árduo dos autores, do comitê do programa e dos organizadores da conferência."
Developer-related factors in change prediction: an empirical assessment,Fatores relacionados ao desenvolvedor na previsão de mudanças: uma avaliação empírica,"Catolino, Gemma and Palomba, Fabio and De Lucia, Andrea and Ferrucci, Filomena and Zaidman, Andy","Predicting the areas of the source code having a higher likelihood to change in the future is a crucial activity to allow developers to plan preventive maintenance operations such as refactoring or peer-code reviews. In the past the research community was active in devising change prediction models based on structural metrics extracted from the source code. More recently, Elish et al. showed how evolution metrics can be more efficient for predicting change-prone classes. In this paper, we aim at making a further step ahead by investigating the role of different developer-related factors, which are able to capture the complexity of the development process under different perspectives, in the context of change prediction. We also compared such models with existing change-prediction models based on evolution and code metrics. Our findings reveal the capabilities of developer-based metrics in identifying classes of a software system more likely to be changed in the future. Moreover, we observed interesting complementarities among the experimented prediction models, that may possibly lead to the definition of new combined models exploiting developer-related factors as well as product and evolution metrics.","Prever as áreas do código-fonte com maior probabilidade de mudar no futuro é uma atividade crucial para permitir que os desenvolvedores planejem operações de manutenção preventiva, como refatoração ou revisões de código por pares. No passado, a comunidade de investigação esteve activa na concepção de modelos de previsão de mudanças baseados em métricas estruturais extraídas do código-fonte. Mais recentemente, Elish et al. mostrou como as métricas de evolução podem ser mais eficientes para prever classes propensas a mudanças. Neste artigo, pretendemos dar mais um passo à frente, investigando o papel de diferentes fatores relacionados ao desenvolvedor, que são capazes de capturar a complexidade do processo de desenvolvimento sob diferentes perspectivas, no contexto da previsão de mudanças. Também comparamos esses modelos com modelos existentes de previsão de mudanças baseados em evolução e métricas de código. Nossas descobertas revelam as capacidades das métricas baseadas no desenvolvedor na identificação de classes de um sistema de software com maior probabilidade de serem alteradas no futuro. Além disso, observamos complementaridades interessantes entre os modelos de previsão experimentados, que possivelmente podem levar à definição de novos modelos combinados explorando fatores relacionados ao desenvolvedor, bem como métricas de produto e evolução."
E-Debitum: managing software energy debt,E-Debitum: gestão da dívida energética de software,"Maia, Daniel and Couto, Marco and Saraiva, Jo\~{a}o and Pereira, Rui","This paper extends previous work on the concept of a new software energy metric: Energy Debt. This metric is a reflection on the implied cost, in terms of energy consumption over time, of choosing an energy flawed software implementation over a more robust and efficient, yet time consuming, approach.This paper presents the implementation a SonarQube tool called E-Debitum which calculates the energy debt of Android applications throughout their versions. This plugin uses a robust, well defined, and extendable smell catalog based on current green software literature, with each smell defining the potential energy savings. To conclude, an experimental validation of E-Debitum was executed on 3 popular Android applications with various releases, showing how their energy debt fluctuated throughout releases.","Este artigo amplia trabalhos anteriores sobre o conceito de uma nova métrica energética de software: Dívida Energética. Esta métrica é uma reflexão sobre o custo implícito, em termos de consumo de energia ao longo do tempo, da escolha de uma implementação de software com falhas energéticas em vez de uma abordagem mais robusta e eficiente, mas demorada. Este artigo apresenta a implementação de uma ferramenta SonarQube chamada E-Debitum que calcula a dívida energética de aplicações Android ao longo das suas versões. Este plugin usa um catálogo de cheiros robusto, bem definido e extensível baseado na literatura atual de software verde, com cada cheiro definindo o potencial de economia de energia. Para concluir, uma validação experimental do E-Debitum foi executada em 3 aplicativos Android populares com vários lançamentos, mostrando como sua dívida energética flutuou ao longo dos lançamentos."
SBQS '24: Proceedings of the XXIII Brazilian Symposium on Software Quality,SBQS '24: Anais do XXIII Simpósio Brasileiro de Qualidade de Software,,,#VALUE!
Simulating Software Evolution to Evaluate the Reliability of Early Decision-making among Design Alternatives toward Maintainability,Simulando a evolução do software para avaliar a confiabilidade da tomada de decisão inicial entre alternativas de design em direção à manutenção,"Karanikolas, Chris and Dimitroulakos, Grigoris and Masselos, Konstantinos","Critical decisions among design altern seventh atives with regards to maintainability arise early in the software design cycle. Existing comparison models relayed on the structural evolution of the used design patterns are suitable to support such decisions. However, their effectiveness on predicting maintenance effort is usually verified on a limited number of case studies under heterogeneous metrics. In this article, a multi-variable simulation model for validating the decision-making reliability of the derived formal comparison models for the significant designing problem of recursive hierarchies of part-whole aggregations, proposed in our prior work, is introduced. In the absence of a strict validation, the simulation model has been thoroughly calibrated concerning its decision-making precision based on empirical distributions from time-series analysis, approximating the highly uncertain nature of actual maintenance process. The decision reliability of the formal models has been statistically validated on a sample of 1,000 instances of design attributes representing the entire design space of the problem. Despite the limited accuracy of measurements, the results show that the models demonstrate an increasing reliability in a long-term perspective, even under assumptions of high variability. Thus, the modeling theory discussed in our prior work delivers reliable models that significantly reduce decision-risk and relevant maintenance cost.","Decisões críticas entre alternativas de projeto com relação à manutenibilidade surgem no início do ciclo de projeto de software. Os modelos de comparação existentes baseados na evolução estrutural dos padrões de projeto utilizados são adequados para apoiar tais decisões. No entanto, a sua eficácia na previsão do esforço de manutenção é geralmente verificada num número limitado de estudos de caso sob métricas heterogéneas. Neste artigo, é apresentado um modelo de simulação multivariável para validar a confiabilidade da tomada de decisão dos modelos de comparação formal derivados para o problema de projeto significativo de hierarquias recursivas de agregações parte-todo, proposto em nosso trabalho anterior. Na ausência de uma validação rigorosa, o modelo de simulação foi minuciosamente calibrado quanto à sua precisão de tomada de decisão com base em distribuições empíricas de análises de séries temporais, aproximando-se da natureza altamente incerta do processo de manutenção real. A confiabilidade da decisão dos modelos formais foi validada estatisticamente em uma amostra de 1.000 instâncias de atributos de projeto representando todo o espaço de projeto do problema. Apesar da precisão limitada das medições, os resultados mostram que os modelos demonstram uma fiabilidade crescente numa perspectiva de longo prazo, mesmo sob pressupostos de elevada variabilidade. Assim, a teoria de modelagem discutida em nosso trabalho anterior fornece modelos confiáveis ​​que reduzem significativamente o risco de decisão e os custos de manutenção relevantes."
Detecting higher-level similarity patterns in programs,Detectando padrões de similaridade de nível superior em programas,"Basit, Hamid Abdul and Jarzabek, Stan","Cloning in software systems is known to create problems during software maintenance. Several techniques have been proposed to detect the same or similar code fragments in software, so-called simple clones. While the knowledge of simple clones is useful, detecting design-level similarities in software could ease maintenance even further, and also help us identify reuse opportunities. We observed that recurring patterns of simple clones - so-called structural clones - often indicate the presence of interesting design-level similarities. An example would be patterns of collaborating classes or components. Finding structural clones that signify potentially useful design information requires efficient techniques to analyze the bulk of simple clone data and making non-trivial inferences based on the abstracted information. In this paper, we describe a practical solution to the problem of detecting some basic, but useful, types of design-level similarities such as groups of highly similar classes or files. First, we detect simple clones by applying conventional token-based techniques. Then we find the patterns of co-occurring clones in different files using the Frequent Itemset Mining (FIM) technique. Finally, we perform file clustering to detect those clusters of highly similar files that are likely to contribute to a design-level similarity pattern. The novelty of our approach is application of data mining techniques to detect design level similarities. Experiments confirmed that our method finds many useful structural clones and scales up to big programs. The paper describes our method for structural clone detection, a prototype tool called Clone Miner that implements the method and experimental results.","Sabe-se que a clonagem em sistemas de software cria problemas durante a manutenção de software. Várias técnicas foram propostas para detectar fragmentos de código iguais ou semelhantes em software, os chamados clones simples. Embora o conhecimento de clones simples seja útil, a detecção de semelhanças em nível de design no software pode facilitar ainda mais a manutenção e também nos ajudar a identificar oportunidades de reutilização. Observamos que padrões recorrentes de clones simples - os chamados clones estruturais - geralmente indicam a presença de semelhanças interessantes em nível de design. Um exemplo seriam padrões de classes ou componentes colaborativos. Encontrar clones estruturais que signifiquem informações de projeto potencialmente úteis requer técnicas eficientes para analisar a maior parte dos dados de clones simples e fazer inferências não triviais com base nas informações abstraídas. Neste artigo, descrevemos uma solução prática para o problema de detecção de alguns tipos básicos, mas úteis, de semelhanças em nível de design, como grupos de classes ou arquivos altamente semelhantes. Primeiro, detectamos clones simples aplicando técnicas convencionais baseadas em tokens. Em seguida, encontramos os padrões de clones co-ocorrentes em diferentes arquivos usando a técnica Frequent Itemset Mining (FIM). Finalmente, realizamos clustering de arquivos para detectar aqueles clusters de arquivos altamente semelhantes que provavelmente contribuirão para um padrão de similaridade em nível de design. A novidade da nossa abordagem é a aplicação de técnicas de mineração de dados para detectar semelhanças em nível de projeto. Experimentos confirmaram que nosso método encontra muitos clones estruturais úteis e pode ser ampliado para grandes programas. O artigo descreve nosso método para detecção de clones estruturais, uma ferramenta protótipo chamada Clone Miner que implementa o método e resultados experimentais."
An empirical investigation into the nature of test smells,Uma investigação empírica sobre a natureza dos cheiros de teste,"Tufano, Michele and Palomba, Fabio and Bavota, Gabriele and Di Penta, Massimiliano and Oliveto, Rocco and De Lucia, Andrea and Poshyvanyk, Denys","Test smells have been defined as poorly designed tests and, as reported by recent empirical studies, their presence may negatively affect comprehension and maintenance of test suites. Despite this, there are no available automated tools to support identification and repair of test smells. In this paper, we firstly investigate developers' perception of test smells in a study with 19 participants. The results show that developers generally do not recognize (potentially harmful) test smells, highlighting that automated tools for identifying such smells are much needed. However, to build effective tools, deeper insights into the test smells phenomenon are required. To this aim, we conducted a large-scale empirical investigation aimed at analyzing (i) when test smells occur in source code, (ii) what their survivability is, and (iii) whether their presence is associated with the presence of design problems in production code (code smells). The results indicate that test smells are usually introduced when the corresponding test code is committed in the repository for the first time, and they tend to remain in a system for a long time. Moreover, we found various unexpected relationships between test and code smells. Finally, we show how the results of this study can be used to build effective automated tools for test smell detection and refactoring.","Os cheiros de teste foram definidos como testes mal elaborados e, conforme relatado por estudos empíricos recentes, sua presença pode afetar negativamente a compreensão e a manutenção dos conjuntos de testes. Apesar disso, não existem ferramentas automatizadas disponíveis para apoiar a identificação e reparação de odores de teste. Neste artigo, investigamos primeiramente a percepção dos desenvolvedores sobre cheiros de teste em um estudo com 19 participantes. Os resultados mostram que os desenvolvedores geralmente não reconhecem cheiros de teste (potencialmente prejudiciais), destacando que ferramentas automatizadas para identificar tais cheiros são muito necessárias. No entanto, para construir ferramentas eficazes, são necessários insights mais profundos sobre o fenômeno dos cheiros de teste. Para tanto, conduzimos uma investigação empírica em larga escala com o objetivo de analisar (i) quando ocorrem cheiros de teste no código-fonte, (ii) qual é sua capacidade de sobrevivência e (iii) se sua presença está associada à presença de problemas de design no código de produção (cheiros de código). Os resultados indicam que os cheiros de teste geralmente são introduzidos quando o código de teste correspondente é confirmado no repositório pela primeira vez e tendem a permanecer no sistema por um longo tempo. Além disso, encontramos várias relações inesperadas entre testes e cheiros de código. Finalmente, mostramos como os resultados deste estudo podem ser usados ​​para construir ferramentas automatizadas eficazes para testar detecção e refatoração de cheiros."
ICSE-NIER '23: Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results,ICSE-NIER '23: Anais da 45ª Conferência Internacional sobre Engenharia de Software: Novas Ideias e Resultados Emergentes,,"ICSE is the leading and by far the largest conference in Software Engineering, attracting researchers, practitioners and students from around the world. ICSE2023 is co-located with 10 conferences and symposia this year, many long-established and prestigious venues in their own right.","ICSE é a principal e de longe a maior conferência em Engenharia de Software, atraindo pesquisadores, profissionais e estudantes de todo o mundo. ICSE2023 está co-localizado com 10 conferências e simpósios este ano, muitos locais de prestígio e de longa data por direito próprio."
SAC '23: Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing,SAC '23: Anais do 38º Simpósio ACM/SIGAPP de Computação Aplicada,,,#VALUE!
Proactive Runtime Detection of Aging-Related Silent Data Corruptions: A Bottom-Up Approach,Detecção proativa em tempo de execução de corrupção silenciosa de dados relacionada ao envelhecimento: uma abordagem de baixo para cima,"Ma, Jiacheng and Ganaiem, Majd and Burbage, Madeline and Gregersen, Theo and McAmis, Rachel and Gabbay, Freddy and Kasikci, Baris","Recent advancements in semiconductor process technologies have unveiled the susceptibility of hardware circuits to reliability issues, especially those related to transistor aging. Transistor aging gradually degrades gate performance, eventually causing hardware to behave incorrectly. Such misbehaving hardware can result in silent data corruptions (SDCs) in software---a type of failure that comes without logs or exceptions, but causes miscomputing instructions, bitflips, and broken cache coherency. Alas, while design efforts can be made to mitigate transistor aging, complete elimination of this problem during design and fabrication cannot be guaranteed. This emerging challenge calls for a mechanism that not only detects potentially aged hardware in the field, but also triggers software mitigations at application runtime.We propose Vega, a novel workflow that allows efficient detection of aging-related failures at software runtime. Vega leverages the well-studied gate-level modeling of aging effects to identify susceptible signal propagation paths that could fail due to transistor aging. It then utilizes formal verification techniques to generate short test cases that activate these paths and detect any failure within them. Vega integrates the test cases into a user application by directly fusing them together, or by packaging the test cases into a library that the application can invoke. We demonstrate our proposed techniques on the arithmetic logic unit and floating-point unit of a RISC-V CPU. We show that Vega generates effective test cases and integrates them into applications with an average of 0.8% performance overhead.","Avanços recentes nas tecnologias de processo de semicondutores revelaram a suscetibilidade dos circuitos de hardware a problemas de confiabilidade, especialmente aqueles relacionados ao envelhecimento dos transistores. O envelhecimento do transistor degrada gradualmente o desempenho do portão, eventualmente fazendo com que o hardware se comporte incorretamente. Esse mau comportamento de hardware pode resultar em corrupções silenciosas de dados (SDCs) no software – um tipo de falha que ocorre sem logs ou exceções, mas causa instruções incorretas, bitflips e quebra de coerência do cache. Infelizmente, embora possam ser feitos esforços de projeto para mitigar o envelhecimento do transistor, a eliminação completa desse problema durante o projeto e a fabricação não pode ser garantida. Este desafio emergente exige um mecanismo que não apenas detecte hardware potencialmente antigo em campo, mas também acione mitigações de software no tempo de execução do aplicativo. Propomos o Vega, um novo fluxo de trabalho que permite a detecção eficiente de falhas relacionadas ao envelhecimento no tempo de execução do software. Vega aproveita a bem estudada modelagem em nível de porta dos efeitos do envelhecimento para identificar caminhos de propagação de sinal suscetíveis que podem falhar devido ao envelhecimento do transistor. Em seguida, utiliza técnicas formais de verificação para gerar casos de teste curtos que ativam esses caminhos e detectam qualquer falha neles. Vega integra os casos de teste em um aplicativo de usuário, fundindo-os diretamente ou empacotando os casos de teste em uma biblioteca que o aplicativo pode invocar. Demonstramos nossas técnicas propostas na unidade lógica aritmética e na unidade de ponto flutuante de uma CPU RISC-V. Mostramos que Vega gera casos de teste eficazes e os integra em aplicações com uma média de sobrecarga de desempenho de 0,8%."
An empirical examination of the relationship between code smells and merge conflicts,Um exame empírico da relação entre cheiros de código e conflitos de mesclagem,"Ahmed, Iftekhar and Brindescu, Caius and Mannan, Umme Ayda and Jensen, Carlos and Sarma, Anita","Background: Merge conflicts are a common occurrence in software development. Researchers have shown the negative impact of conflicts on the resulting code quality and the development workflow. Thus far, no one has investigated the effect of bad design (code smells) on merge conflicts. Aims: We posit that entities that exhibit certain types of code smells are more likely to be involved in a merge conflict. We also postulate that code elements that are both ""smelly"" and involved in a merge conflict are associated with other undesirable effects (more likely to be buggy). Method: We mined 143 repositories from GitHub and recreated 6,979 merge conflicts to obtain metrics about code changes and conflicts. We categorized conflicts into semantic or non-semantic, based on whether changes affected the Abstract Syntax Tree. For each conflicting change, we calculate the number of code smells and the number of future bug-fixes associated with the affected lines of code. Results: We found that entities that are smelly are three times more likely to be involved in merge conflicts. Method-level code smells (Blob Operation and Internal Duplication) are highly correlated with semantic conflicts. We also found that code that is smelly and experiences merge conflicts is more likely to be buggy. Conclusion: Bad code design not only impacts maintainability, it also impacts the day to day operations of a project, such as merging contributions, and negatively impacts the quality of the resulting code. Our findings indicate that research is needed to identify better ways to support merge conflict resolution to minimize its effect on code quality.","Antecedentes: Conflitos de mesclagem são uma ocorrência comum no desenvolvimento de software. Os pesquisadores mostraram o impacto negativo dos conflitos na qualidade do código resultante e no fluxo de trabalho de desenvolvimento. Até agora, ninguém investigou o efeito de um design ruim (cheiros de código) em conflitos de mesclagem. Objetivos: Postulamos que entidades que exibem certos tipos de cheiros de código têm maior probabilidade de se envolver em um conflito de mesclagem. Também postulamos que os elementos de código que são ""fedorentos"" e envolvidos em um conflito de mesclagem estão associados a outros efeitos indesejáveis ​​(com maior probabilidade de apresentar erros). Método: extraímos 143 repositórios do GitHub e recriamos 6.979 conflitos de mesclagem para obter métricas sobre alterações e conflitos de código. Categorizamos os conflitos em semânticos ou não semânticos, com base no fato de as alterações afetarem a árvore de sintaxe abstrata. Para cada alteração conflitante, calculamos o número de cheiros de código e o número de futuras correções de bugs associadas às linhas de código afetadas. Resultados: Descobrimos que entidades malcheirosas têm três vezes mais probabilidade de se envolverem em conflitos de fusão. Os cheiros de código em nível de método (operação de blob e duplicação interna) estão altamente correlacionados com conflitos semânticos. Também descobrimos que o código que cheira mal e apresenta conflitos de mesclagem tem maior probabilidade de apresentar erros. Conclusão: O design incorreto do código não afeta apenas a capacidade de manutenção, mas também as operações diárias de um projeto, como a fusão de contribuições, e impacta negativamente a qualidade do código resultante. Nossas descobertas indicam que são necessárias pesquisas para identificar melhores maneiras de apoiar a resolução de conflitos de mesclagem para minimizar seu efeito na qualidade do código."
From run-time behavior to usage scenarios: an interaction-pattern mining approach,Do comportamento em tempo de execução aos cenários de uso: uma abordagem de mineração de padrões de interação,"El-Ramly, Mohammad and Stroulia, Eleni and Sorenson, Paul","A key challenge facing IT organizations today is their evolution towards adopting e-business practices that gives rise to the need for reengineering their underlying software systems. Any reengineering effort has to be aware of the functional requirements of the subject system, in order not to violate the integrity of its intended uses. However, as software systems get regularly maintained throughout their lifecycle, the documentation of their requirements often become obsolete or get lost. To address this problem of ""software requirements loss"", we have developed an interaction-pattern mining method for the recovery of functional requirements as usage scenarios. Our method analyzes traces of the run-time system-user interaction to discover frequently recurring patterns; these patterns correspond to the functionality currently exercised by the system users, represented as usage scenarios. The discovered scenarios provide the basis for reengineering the software system into web-accessible components, each one supporting one of the discovered scenarios. In this paper, we describe IPM2, our interaction-pattern discovery algorithm, we illustrate it with a case study from a real application and we give an overview of the reengineering process in the context of which it is employed.","Um dos principais desafios que as organizações de TI enfrentam hoje é a sua evolução no sentido da adopção de práticas de e-business, o que dá origem à necessidade de reengenharia dos seus sistemas de software subjacentes. Qualquer esforço de reengenharia deve estar ciente dos requisitos funcionais do sistema em questão, a fim de não violar a integridade dos usos pretendidos. No entanto, à medida que os sistemas de software são mantidos regularmente ao longo do seu ciclo de vida, a documentação dos seus requisitos muitas vezes torna-se obsoleta ou perde-se. Para resolver este problema de “perda de requisitos de software”, desenvolvemos um método de mineração de padrões de interação para a recuperação de requisitos funcionais como cenários de uso. Nosso método analisa traços da interação sistema-usuário em tempo de execução para descobrir padrões recorrentes com frequência; esses padrões correspondem às funcionalidades atualmente exercidas pelos usuários do sistema, representadas como cenários de utilização. Os cenários descobertos fornecem a base para a reengenharia do sistema de software em componentes acessíveis pela web, cada um suportando um dos cenários descobertos. Neste artigo, descrevemos o IPM2, nosso algoritmo de descoberta de padrões de interação, ilustramos-o com um estudo de caso de uma aplicação real e damos uma visão geral do processo de reengenharia no contexto em que ele é empregado."
Managing Data and Artifacts between Software Engineers and Artists: an ISSv2 Case Study,Gerenciando dados e artefatos entre engenheiros de software e artistas: um estudo de caso ISSv2,"Mokhov, Serguei A. and Song, Miao and Kaur, Amandeep and Talwar, Mehak and Gudavalli, Keerthana and Mudur, Sudhir P.","We describe our experience of managing different types of artifacts between multidisciplinary teams of computer scientists and software engineers with computation and design artists while designing, developing, and deploying Illimitable Space System v2 (ISSv2) in real production environments. The artifacts include design documentation, source code, hardware and production equipment inventory, stage data, SCM and issue tracking data, git repository, and multimedia assets. These types of projects are challenging due to the nature of interdisciplinary teams and their working habits. We show how we manage the data and the teams to have enable successful public productions.","Descrevemos nossa experiência no gerenciamento de diferentes tipos de artefatos entre equipes multidisciplinares de cientistas da computação e engenheiros de software com artistas de computação e design enquanto projetamos, desenvolvemos e implantamos o Illimitable Space System v2 (ISSv2) em ambientes reais de produção. Os artefatos incluem documentação de design, código-fonte, inventário de hardware e equipamentos de produção, dados de estágio, SCM e dados de rastreamento de problemas, repositório git e ativos multimídia. Esses tipos de projetos são desafiadores devido à natureza das equipes interdisciplinares e aos seus hábitos de trabalho. Mostramos como gerenciamos os dados e as equipes para possibilitar produções públicas de sucesso."
A method for detecting faulty code violating implicit coding rules,Um método para detectar código defeituoso que viola regras de codificação implícitas,"Matsumura, Tomoko and Monden, Akito and Matsumoto, Ken-ichi","In the field of legacy software maintenance, there unexpectedly arise a large number of implicit coding rules --- which are seldom written down in specification documents or design documents --- as software becomes more complicated than it used be. Since not all the members in a maintenance team realize each of implicit coding rules, a maintainer who is not aware of a rule often violates the rule while doing various maintenance activities such as adding new functionality and repairing faults. The problem here is not only such a violation causes injection of a new fault into software but also this violation will be repeated again and again in the future by different maintainers. Indeed, we found that 32.7% of faults of certain legacy software were due to such violations.This paper proposes a method for detecting code fragments that violate implicit coding rules. In the method, an expert maintainer firstly investigates the causes, situations, and code fragments of each fault described in bug reports; and, identifies implicit coding rules as much as possible. Then, code patterns violating the rules (which we call bug code patterns) are described in a pattern description language. Finally, potential faulty code fragments are extracted by a pattern matching technique.","No campo da manutenção de software legado, surge inesperadamente um grande número de regras de codificação implícitas – que raramente são escritas em documentos de especificação ou de design – à medida que o software se torna mais complicado do que costumava ser. Como nem todos os membros de uma equipe de manutenção percebem cada uma das regras de codificação implícitas, um mantenedor que não tem conhecimento de uma regra frequentemente viola a regra ao realizar diversas atividades de manutenção, como adicionar novas funcionalidades e reparar falhas. O problema aqui não é apenas que tal violação causa a injeção de uma nova falha no software, mas também que essa violação será repetida continuamente no futuro por diferentes mantenedores. Na verdade, descobrimos que 32,7% das falhas de determinados softwares legados foram devidas a tais violações. Este artigo propõe um método para detectar fragmentos de código que violam regras de codificação implícitas. No método, um mantenedor especialista investiga primeiro as causas, situações e fragmentos de código de cada falha descrita nos relatórios de bugs; e identifica regras de codificação implícitas tanto quanto possível. Então, os padrões de código que violam as regras (que chamamos de padrões de código de bug) são descritos em uma linguagem de descrição de padrões. Finalmente, potenciais fragmentos de código defeituosos são extraídos por uma técnica de correspondência de padrões."
ICCBDC '22: Proceedings of the 2022 6th International Conference on Cloud and Big Data Computing,ICCBDC '22: Anais da 6ª Conferência Internacional sobre Computação em Nuvem e Big Data de 2022,,,#VALUE!
Detecting missing method calls as violations of the majority rule,Detectando chamadas de método ausentes como violações da regra da maioria,"Monperrus, Martin and Mezini, Mira","When using object-oriented frameworks it is easy to overlook certain important method calls that are required at particular places in code. In this article, we provide a comprehensive set of empirical facts on this problem, starting from traces of missing method calls in a bug repository. We propose a new system that searches for missing method calls in software based on the other method calls that are observable. Our key insight is that the voting theory concept of majority rule holds for method calls: a call is likely to be missing if there is a majority of similar pieces of code where this call is present. The evaluation shows that the system predictions go further missing method calls and often reveal different kinds of code smells (e.g., violations of API best practices).","Ao usar estruturas orientadas a objetos, é fácil ignorar certas chamadas de métodos importantes que são necessárias em locais específicos do código. Neste artigo, fornecemos um conjunto abrangente de fatos empíricos sobre esse problema, começando com rastros de chamadas de métodos ausentes em um repositório de bugs. Propomos um novo sistema que procura chamadas de métodos ausentes em software com base em outras chamadas de métodos observáveis. Nosso principal insight é que o conceito da teoria da votação de regra da maioria é válido para chamadas de método: é provável que uma chamada esteja faltando se houver uma maioria de trechos de código semelhantes onde essa chamada estiver presente. A avaliação mostra que as previsões do sistema vão além das chamadas de método e muitas vezes revelam diferentes tipos de cheiros de código (por exemplo, violações das práticas recomendadas da API)."
ICSE-Companion '24: Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings,ICSE-Companion '24: Procedimentos da 46ª Conferência Internacional IEEE/ACM 2024 sobre Engenharia de Software: Procedimentos Complementares,,"ICSE is the leading and, by far, the largest conference in Software Engineering, attracting researchers, practitioners, and students worldwide. ICSE2024 is co-located with 11 conferences and symposia this year, many long-established and prestigious venues in their own right.","ICSE é a principal e, de longe, a maior conferência em Engenharia de Software, atraindo pesquisadores, profissionais e estudantes de todo o mundo. ICSE2024 está co-localizado com 11 conferências e simpósios este ano, muitos locais de prestígio e de longa data por direito próprio."
Refactoring for software architecture smells,Refatoração para cheiros de arquitetura de software,"Samarthyam, Ganesh and Suryanarayana, Girish and Sharma, Tushar","Code smells and refactoring have received considerable interest from the academia as well as from the industry in the past two decades. The interest has given birth to various tools, processes, techniques, and practices to identify smells and refactor them. Despite the high interest, architecture smells and corresponding refactorings haven't received as much focus and adoption from the software engineering community. In this paper, we motivate the need of architecture refactoring, discuss the current related research, and present a few potential research directions for architecture refactoring.","Os cheiros de código e a refatoração têm recebido considerável interesse da academia e também da indústria nas últimas duas décadas. O interesse deu origem a diversas ferramentas, processos, técnicas e práticas para identificar cheiros e refatorá-los. Apesar do grande interesse, os cheiros de arquitetura e as refatorações correspondentes não receberam tanto foco e adoção da comunidade de engenharia de software. Neste artigo, motivamos a necessidade de refatoração de arquitetura, discutimos as pesquisas atuais relacionadas e apresentamos algumas direções de pesquisa potenciais para refatoração de arquitetura."
Continuous detection of design flaws in evolving object-oriented programs using incremental multi-pattern matching,Detecção contínua de falhas de projeto em programas orientados a objetos em evolução usando correspondência incremental de vários padrões,"Peldszus, Sven and Kulcs\'{a}r, G\'{e}za and Lochau, Malte and Schulze, Sandro","Design flaws in object-oriented programs may seriously corrupt code quality thus increasing the risk for introducing subtle errors during software maintenance and evolution. Most recent approaches identify design flaws in an ad-hoc manner, either focusing on software metrics, locally restricted code smells, or on coarse-grained architectural anti-patterns. In this paper, we utilize an abstract program model capturing high-level object-oriented code entities, further augmented with qualitative and quantitative design-related information such as coupling/cohesion. Based on this model, we propose a comprehensive methodology for specifying object-oriented design flaws by means of compound rules integrating code metrics, code smells and anti-patterns in a modular way. This approach allows for efficient, automated design-flaw detection through incremental multi-pattern matching, by facilitating systematic information reuse among multiple detection rules as well as between subsequent detection runs on continuously evolving programs. Our tool implementation comprises well-known anti-patterns for Java programs. The results of our experimental evaluation show high detection precision, scalability to real-size programs, as well as a remarkable gain in efficiency due to information reuse.","Falhas de projeto em programas orientados a objetos podem corromper seriamente a qualidade do código, aumentando assim o risco de introdução de erros sutis durante a manutenção e evolução do software. As abordagens mais recentes identificam falhas de design de maneira ad-hoc, concentrando-se em métricas de software, cheiros de código restritos localmente ou em antipadrões arquitetônicos de granulação grossa. Neste artigo, utilizamos um modelo de programa abstrato que captura entidades de código orientadas a objetos de alto nível, complementadas com informações qualitativas e quantitativas relacionadas ao design, como acoplamento/coesão. Com base neste modelo, propomos uma metodologia abrangente para especificar falhas de projeto orientadas a objetos por meio de regras compostas integrando métricas de código, cheiros de código e antipadrões de forma modular. Essa abordagem permite a detecção eficiente e automatizada de falhas de projeto por meio da correspondência incremental de vários padrões, facilitando a reutilização sistemática de informações entre múltiplas regras de detecção, bem como entre execuções de detecção subsequentes em programas em constante evolução. Nossa implementação de ferramenta compreende antipadrões bem conhecidos para programas Java. Os resultados da nossa avaliação experimental mostram alta precisão de detecção, escalabilidade para programas de tamanho real, bem como um notável ganho de eficiência devido à reutilização de informações."
Active hotspot: an issue-oriented model to monitor software evolution and degradation,Hotspot ativo: um modelo orientado a problemas para monitorar a evolução e degradação de software,"Feng, Qiong and Cai, Yuanfang and Kazman, Rick and Cui, Di and Liu, Ting and Fang, Hongzhou","Architecture degradation has a strong negative impact on software quality and can result in significant losses. Severe software degradation does not happen overnight. Software evolves continuously, through numerous issues, fixing bugs and adding new features, and architecture flaws emerge quietly and largely unnoticed until they grow in scope and significance when the system becomes difficult to maintain. Developers are largely unaware of these flaws or the accumulating debt as they are focused on their immediate tasks of address individual issues. As a consequence, the cumulative impacts of their activities, as they affect the architecture, go unnoticed. To detect these problems early and prevent them from accumulating into severe ones we propose to monitor software evolution by tracking the interactions among files revised to address issues. In particular, we propose and show how we can automatically detect active hotspots, to reveal architecture problems. We have studied hundreds of hotspots along the evolution timelines of 21 open source projects and showed that there exist just a few dominating active hotspots per project at any given time. Moreover, these dominating active hotspots persist over long time periods, and thus deserve special attention. Compared with state-of-the-art design and code smell detection tools we report that, using active hotspots, it is possible to detect signs of software degradation both earlier and more precisely.","A degradação da arquitetura tem um forte impacto negativo na qualidade do software e pode resultar em perdas significativas. A degradação severa do software não acontece da noite para o dia. O software evolui continuamente, através de vários problemas, corrigindo bugs e adicionando novos recursos, e as falhas de arquitetura surgem silenciosamente e em grande parte despercebidas até crescerem em escopo e importância quando o sistema se torna difícil de manter. Os promotores desconhecem em grande parte estas falhas ou a dívida acumulada, uma vez que estão concentrados nas suas tarefas imediatas de resolução de questões individuais. Como consequência, os impactos cumulativos das suas atividades, à medida que afetam a arquitetura, passam despercebidos. Para detectar esses problemas precocemente e evitar que eles se acumulem em problemas graves, propomos monitorar a evolução do software rastreando as interações entre os arquivos revisados ​​para resolver os problemas. Em particular, propomos e mostramos como podemos detectar automaticamente hotspots ativos, para revelar problemas de arquitetura. Estudamos centenas de hotspots ao longo dos cronogramas de evolução de 21 projetos de código aberto e mostramos que existem apenas alguns hotspots ativos dominantes por projeto em um determinado momento. Além disso, estes hotspots activos dominantes persistem durante longos períodos de tempo e, portanto, merecem atenção especial. Em comparação com ferramentas de design e detecção de cheiro de código de última geração, relatamos que, usando pontos de acesso ativos, é possível detectar sinais de degradação de software de forma mais precoce e precisa."
Topic modeling of NASA space system problem reports: research in practice,Modelagem de tópicos de relatórios de problemas do sistema espacial da NASA: pesquisa na prática,"Layman, Lucas and Nikora, Allen P. and Meek, Joshua and Menzies, Tim","Problem reports at NASA are similar to bug reports: they capture defects found during test, post-launch operational anomalies, and document the investigation and corrective action of the issue. These artifacts are a rich source of lessons learned for NASA, but are expensive to analyze since problem reports are comprised primarily of natural language text. We apply topic modeling to a corpus of NASA problem reports to extract trends in testing and operational failures. We collected 16,669 problem reports from six NASA space flight missions and applied Latent Dirichlet Allocation topic modeling to the document corpus. We analyze the most popular topics within and across missions, and how popular topics changed over the lifetime of a mission. We find that hardware material and flight software issues are common during the integration and testing phase, while ground station software and equipment issues are more common during the operations phase. We identify a number of challenges in topic modeling for trend analysis: 1) that the process of selecting the topic modeling parameters lacks definitive guidance, 2) defining semantically-meaningful topic labels requires non-trivial effort and domain expertise, 3) topic models derived from the combined corpus of the six missions were biased toward the larger missions, and 4) topics must be semantically distinct as well as cohesive to be useful. Nonetheless, topic modeling can identify problem themes within missions and across mission lifetimes, providing useful feedback to engineers and project managers.","Os relatórios de problemas na NASA são semelhantes aos relatórios de bugs: eles capturam defeitos encontrados durante o teste, anomalias operacionais pós-lançamento e documentam a investigação e ação corretiva do problema. Esses artefatos são uma fonte rica de lições aprendidas para a NASA, mas sua análise é cara, uma vez que os relatórios de problemas são compostos principalmente de texto em linguagem natural. Aplicamos modelagem de tópicos a um corpus de relatórios de problemas da NASA para extrair tendências em testes e falhas operacionais. Coletamos 16.669 relatórios de problemas de seis missões de voo espacial da NASA e aplicamos a modelagem de tópicos de Alocação Latente de Dirichlet ao corpus do documento. Analisamos os tópicos mais populares dentro e entre missões, e como os tópicos populares mudaram ao longo da vida de uma missão. Descobrimos que problemas com materiais de hardware e software de voo são comuns durante a fase de integração e teste, enquanto problemas com software e equipamentos da estação terrestre são mais comuns durante a fase de operações. Identificamos uma série de desafios na modelagem de tópicos para análise de tendências: 1) que o processo de seleção dos parâmetros de modelagem de tópicos carece de orientação definitiva, 2) definir rótulos de tópicos semanticamente significativos requer esforço não trivial e conhecimento de domínio, 3) modelos de tópicos derivados do corpus combinado das seis missões foram tendenciosos para as missões maiores, e 4) os tópicos devem ser semanticamente distintos, bem como coesos para serem úteis. No entanto, a modelagem de tópicos pode identificar temas problemáticos dentro das missões e ao longo da vida das missões, fornecendo feedback útil para engenheiros e gerentes de projeto."
LADC '24: Proceedings of the 13th Latin-American Symposium on Dependable and Secure Computing,LADC '24: Anais do 13º Simpósio Latino-Americano sobre Computação Confiável e Segura,,,#VALUE!
"Maintenance Operations on Cloud, Edge, and IoT Environments: Taxonomy, Survey, and Research Challenges","Operações de manutenção em ambientes de nuvem, borda e IoT: taxonomia, levantamento e desafios de pesquisa","Souza, Paulo and Ferreto, Tiago and Calheiros, Rodrigo","The emergence of the Internet of Things (IoT) introduced new classes of applications whose latency and bandwidth requirements could not be satisfied by the traditional Cloud Computing model. Consequently, the Internet Technology community promoted the cooperation of two paradigms, Cloud Computing and Edge Computing, combining large-scale computing power and real-time processing capabilities. A significant management challenge in such complex infrastructure concerns the development of efficient maintenance strategies to preserve the environment’s performance and security. While the abundant resources from the academic literature could support the design of novel maintenance solutions, extracting actionable insights from the existing approaches is challenging, given the massive number of published papers. Furthermore, existing review papers, which could help summarize the state-of-the-art, scope their investigations to the maintenance of certain components in particular scenarios. This work fills this gap with a broader literature analysis that covers maintenance strategies targeting physical and logical components in cloud, edge, and IoT environments. First, we introduce a taxonomy that organizes existing solutions according to several characteristics. Then, we review the literature following the taxonomy structure to facilitate the understanding of the research landscape and the comparison between existing works. Finally, we shed light on open challenges that represent promising research directions.","O surgimento da Internet das Coisas (IoT) introduziu novas classes de aplicações cujos requisitos de latência e largura de banda não poderiam ser satisfeitos pelo modelo tradicional de Cloud Computing. Consequentemente, a comunidade de Tecnologia da Internet promoveu a cooperação de dois paradigmas, Cloud Computing e Edge Computing, combinando poder de computação em grande escala e capacidades de processamento em tempo real. Um desafio significativo de gestão em infraestruturas tão complexas diz respeito ao desenvolvimento de estratégias de manutenção eficientes para preservar o desempenho e a segurança do ambiente. Embora os recursos abundantes da literatura académica possam apoiar a concepção de novas soluções de manutenção, extrair conhecimentos práticos das abordagens existentes é um desafio, dado o enorme número de artigos publicados. Além disso, os documentos de revisão existentes, que poderiam ajudar a resumir o estado da arte, abrangem as suas investigações para a manutenção de certos componentes em cenários específicos. Este trabalho preenche essa lacuna com uma análise mais ampla da literatura que abrange estratégias de manutenção direcionadas a componentes físicos e lógicos em ambientes de nuvem, edge e IoT. Primeiro, apresentamos uma taxonomia que organiza as soluções existentes de acordo com diversas características. Em seguida, revisamos a literatura seguindo a estrutura da taxonomia para facilitar a compreensão do cenário da pesquisa e a comparação entre os trabalhos existentes. Finalmente, lançamos luz sobre desafios abertos que representam direções de pesquisa promissoras."
ESEC/FSE 2023: Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering,ESEC/FSE 2023: Anais da 31ª Conferência Conjunta Europeia de Engenharia de Software e Simpósio sobre os Fundamentos da Engenharia de Software da ACM,,"We are pleased to welcome all delegates to ESEC/FSE 2023, the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. ESEC/FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.","Temos o prazer de dar as boas-vindas a todos os delegados à ESEC/FSE 2023, a Conferência Conjunta Europeia de Engenharia de Software e Simpósio sobre os Fundamentos da Engenharia de Software da ACM. ESEC/FSE é um fórum de renome internacional para investigadores, profissionais e educadores apresentarem e discutirem as mais recentes inovações, tendências, experiências e desafios no campo da engenharia de software. A ESEC/FSE reúne especialistas da academia e da indústria para partilhar os mais recentes resultados e tendências de investigação, bem como a sua aplicação prática em todas as áreas da engenharia de software."
On the effect of incompleteness to check requirement-to-method traces,Sobre o efeito da incompletude na verificação dos rastreamentos do requisito ao método,"Hammoudi, Mouna and Mayr-Dorn, Christoph and Mashkoor, Atif and Egyed, Alexander","Requirement-to-method traces reveal the code location(s) where a requirement is implemented. This is helpful to software engineers when they have to perform tasks such as software maintenance or bug fixing. Indeed, being aware of the method(s) that implement a requirement saves engineers' time, as it pinpoints the exact code region that needs to be edited to perform a bug fix or a maintenance task. Engineers produce traces manually as well as automatically. Nevertheless, traces are incomplete. This limits the amount of information that could be used by an automated technique to check further traces. Therefore, since traces are incomplete, we would like to study the effect of incompleteness on the automated assessment of requirement-to-method traces. In this paper, we apply machine learning on either incomplete or complete tracing information and we evaluate the effect of incompleteness on checking trace information. We demonstrate that the use of complete traces might yield a higher precision but yields a lower recall. Also, the use of incomplete traces yields a higher recall but a lower precision.","Os rastreamentos do requisito ao método revelam os locais do código onde um requisito é implementado. Isso é útil para engenheiros de software quando eles precisam realizar tarefas como manutenção de software ou correção de bugs. Na verdade, estar ciente dos métodos que implementam um requisito economiza tempo dos engenheiros, pois identifica a região exata do código que precisa ser editada para executar uma correção de bug ou uma tarefa de manutenção. Os engenheiros produzem traços manualmente e também automaticamente. No entanto, os vestígios estão incompletos. Isto limita a quantidade de informação que poderia ser usada por uma técnica automatizada para verificar vestígios adicionais. Portanto, como os rastreamentos são incompletos, gostaríamos de estudar o efeito da incompletude na avaliação automatizada dos rastreamentos de requisitos para métodos. Neste artigo, aplicamos aprendizado de máquina em informações de rastreamento incompletas ou completas e avaliamos o efeito da incompletude na verificação de informações de rastreamento. Demonstramos que o uso de traços completos pode produzir uma precisão maior, mas produz uma recuperação menor. Além disso, o uso de traços incompletos produz uma recuperação maior, mas uma precisão menor."
FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering,FSE 2024: Anais complementares da 32ª Conferência Internacional ACM sobre os Fundamentos da Engenharia de Software,,"We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.","Temos o prazer de dar as boas-vindas a todos os delegados à FSE 2024, a Conferência Internacional ACM sobre os Fundamentos da Engenharia de Software (FSE) 2024. A conferência agora tem um nome mais curto! FSE é um fórum de renome internacional para pesquisadores, profissionais e educadores apresentarem e discutirem as mais recentes inovações, tendências, experiências e desafios no campo da engenharia de software. A FSE reúne especialistas da academia e da indústria para compartilhar os mais recentes resultados e tendências de pesquisas, bem como sua aplicação prática em todas as áreas da engenharia de software."
"ARCADE: an extensible workbench for architecture recovery, change, and decay evaluation","ARCADE: um ambiente de trabalho extensível para recuperação, mudança e avaliação de deterioração de arquitetura","Schmitt Laser, Marcelo and Medvidovic, Nenad and Le, Duc Minh and Garcia, Joshua","This paper presents the design, implementation, and usage details of ARCADE, an extensible workbench for supporting the recovery of software systems' architectures, and for evaluating architectural change and decay. ARCADE has been developed and maintained over the past decade, and has been deployed in a number of research labs as well as within three large companies. ARCADE's implementation is available at https://bitbucket.org/joshuaga/arcade and the video depicting its use at https://tinyurl.com/arcade-tool-demo.","Este artigo apresenta detalhes de projeto, implementação e uso do ARCADE, um ambiente de trabalho extensível para apoiar a recuperação de arquiteturas de sistemas de software e para avaliar mudanças e decadências arquitetônicas. O ARCADE foi desenvolvido e mantido ao longo da última década e foi implantado em vários laboratórios de pesquisa, bem como em três grandes empresas. A implementação do ARCADE está disponível em https://bitbucket.org/joshuaga/arcade e o vídeo que descreve seu uso em https://tinyurl.com/arcade-tool-demo."
Feature Selection Techniques to Counter Class Imbalance Problem for Aging Related Bug Prediction: Aging Related Bug Prediction,Técnicas de seleção de recursos para combater o problema de desequilíbrio de classe para previsão de bugs relacionados ao envelhecimento: previsão de bugs relacionados ao envelhecimento,"Kumar, Lov and Sureka, Ashish","Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs.We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and five different strategies (Random Under-sampling, Random Oversampling, SMOTE, SMOTEBoost and RUSBoost) to counter the effect of class imbalance in our proposed machine learning based solution approach. Experimental results reveal that the random under-sampling approach performs best followed by RUSBoost in-terms of the mean AUC metric. Statistical significance test demonstrates that there is a significant difference between the performance of the various feature selection techniques. Experimental results shows that Gain Ratio and RELEIF performs best in comparison to other strategies to address the class imbalance problem. We infer from the statistical significance test that there is no difference between the performances of the five different learning algorithms.","Bugs relacionados ao envelhecimento (ARBs) ocorrem em sistemas de longa execução devido a condições de erro causadas pelo acúmulo de problemas, como vazamento de memória ou arquivos e bloqueios não lançados. Bugs relacionados ao envelhecimento são difíceis de descobrir durante os testes de software e também difíceis de replicar. A identificação e previsão automáticas de arquivos e classes sujeitos a falhas relacionados ao envelhecimento em um sistema orientado a objetos podem ajudar a equipe de garantia de qualidade de software a otimizar seus esforços de teste. Neste artigo, apresentamos um estudo sobre a aplicação de métricas estáticas de código-fonte e técnicas de aprendizado de máquina para prever bugs relacionados ao envelhecimento. Conduzimos uma série de experimentos em conjuntos de dados disponíveis publicamente de dois grandes sistemas de software de código aberto: Linux e MySQL. Desequilíbrio de classe e alta dimensionalidade são os dois principais desafios técnicos na construção de preditores eficazes para bugs relacionados ao envelhecimento. Investigamos a aplicação de cinco técnicas diferentes de seleção de recursos (OneR, ganho de informação, taxa de ganho, RELEIF e incerteza simétrica) para redução de dimensionalidade e cinco estratégias diferentes (subamostragem aleatória, sobreamostragem aleatória, SMOTE, SMOTEBoost e RUSBoost) para combater o efeito do desequilíbrio de classe em nossa abordagem de solução proposta baseada em aprendizado de máquina. Os resultados experimentais revelam que a abordagem de subamostragem aleatória tem melhor desempenho seguida pelo RUSBoost em termos da métrica média de AUC. O teste de significância estatística demonstra que existe uma diferença significativa entre o desempenho das diversas técnicas de seleção de recursos. Os resultados experimentais mostram que Gain Ratio e RELEIF apresentam melhor desempenho em comparação com outras estratégias para resolver o problema de desequilíbrio de classe. Inferimos do teste de significância estatística que não há diferença entre os desempenhos dos cinco algoritmos de aprendizagem diferentes."
A Survey of AIOps Methods for Failure Management,Uma pesquisa de métodos AIOps para gerenciamento de falhas,"Notaro, Paolo and Cardoso, Jorge and Gerndt, Michael","Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.","A sociedade moderna está cada vez mais migrando para sistemas de computação complexos e distribuídos. O aumento da escala e da complexidade destes sistemas desafia as equipas de O&M que realizam operações diárias de monitorização e reparação, em contraste com a crescente procura de fiabilidade e escalabilidade das aplicações modernas. Por esta razão, o estudo de sistemas de monitoramento automatizados e inteligentes despertou recentemente muito interesse na indústria de TI aplicada e na academia. A Inteligência Artificial para Operações de TI (AIOps) foi proposta para enfrentar os desafios modernos de administração de TI graças ao aprendizado de máquina, IA e Big Data. No entanto, o AIOps como tópico de investigação ainda é largamente desestruturado e inexplorado, devido à falta de convenções na categorização de contribuições para os seus requisitos de dados, objetivos alvo e componentes. Neste trabalho, focamos em AIOps para Gerenciamento de Falhas (FM), caracterizando e descrevendo 5 categorias diferentes e 14 subcategorias de contribuições, com base em sua janela de tempo de intervenção e no problema alvo a ser resolvido. Revisamos 100 soluções de FM, com foco nos requisitos de aplicabilidade e nos resultados quantitativos alcançados, para facilitar uma aplicação eficaz de soluções AIOps. Por fim, discutimos os problemas atuais de desenvolvimento nas áreas cobertas pela AIOps e delineamos possíveis tendências futuras para o gerenciamento de falhas baseado em IA."
Mining Discussions on Software Migration: A study of the Boost mailing list regarding C++ code evolution,Discussões de mineração sobre migração de software: um estudo da lista de discussão Boost sobre a evolução do código C++,"Carvalho, Pedro V. R. de and Bonif\'{a}cio, Rodrigo and Lucas, Walter and Mota, Alana Paula Barbosa","Programming languages are evolving faster than ever before. New versions of mainstream programming languages (e.g., C++, Java, and JavaScript) are being released with increasing frequency, posing an elevated challenge for software developers as their systems are more easily affected by obsolescence. Software migration is far from trivial. Although there is literature on software migration methods and how developers deal with the software aging and obsolescence, little research exists on how developers perceive and are affected by rapid programming language evolution. To understand how C++ developers discuss these issues and the nature of their discussions, we mined the mailing lists of the Boost organization—one of the most important C++ open-source communities. We found that software migration is a significant concern for this community, with a lasting presence in their message boards. Furthermore, most discussions related to the challenges of the migration process, with many conflicting opinions on related matters, suggesting these issues are not easily solvable.","As linguagens de programação estão evoluindo mais rápido do que nunca. Novas versões das principais linguagens de programação (por exemplo, C++, Java e JavaScript) estão sendo lançadas com frequência cada vez maior, representando um desafio elevado para os desenvolvedores de software, pois seus sistemas são mais facilmente afetados pela obsolescência. A migração de software está longe de ser trivial. Embora exista literatura sobre métodos de migração de software e como os desenvolvedores lidam com o envelhecimento e a obsolescência do software, existem poucas pesquisas sobre como os desenvolvedores percebem e são afetados pela rápida evolução da linguagem de programação. Para entender como os desenvolvedores de C++ discutem essas questões e a natureza de suas discussões, exploramos as listas de discussão da organização Boost – uma das comunidades de código aberto C++ mais importantes. Descobrimos que a migração de software é uma preocupação significativa para esta comunidade, com uma presença duradoura nos seus fóruns. Além disso, a maioria das discussões relacionava-se com os desafios do processo de migração, com muitas opiniões contraditórias sobre assuntos relacionados, sugerindo que estas questões não são facilmente solucionáveis."
Effects of Visualizing Technical Debts on a Software Maintenance Project,Efeitos da visualização de dívidas técnicas em um projeto de manutenção de software,"Dias, Ronivon Silva and de Alc\^{a}ntara dos Santos Neto, Pedro and de Sousa Ibiapina, Irvayne Matheus and Avelino, Guilherme Amaral and da Costa Castro, Ot\'{a}vio Cury","The technical debt (TD) metaphor is widely used to encapsulate numerous software quality problems. She describes the trade-off between the short term benefit of taking a shortcut during the design or implementation phase of a software product (for example, in order to meet a deadline) and the long term consequences of taking said shortcut, which may affect the quality of the software product. TDs must be managed to guarantee the software quality and also reduce its maintenance and evolution costs. However, the tools for TD detection usually provide results only considering the files perspective (class and methods), that is not usual during the project management. In this work, a technique is proposed to identify/visualize TD on a new perspective: software features. The proposed technique adopts Mining Software Repository (MRS) tools to identify the software features and after the technical debts that affect these features. Additionally, we also proposed an approach to support maintenance tasks guided by TD visualization at the feature level aiming to evaluate its applicability on real software projects. The results indicate that the approach can be useful to decrease the existent TDs, as well as avoid the introduction of new TDs.","A metáfora da dívida técnica (TD) é amplamente utilizada para encapsular vários problemas de qualidade de software. Ela descreve o compromisso entre o benefício a curto prazo de tomar um atalho durante a fase de concepção ou implementação de um produto de software (por exemplo, para cumprir um prazo) e as consequências a longo prazo de tomar esse atalho, que podem afectar a qualidade do produto de software. Os TDs devem ser gerenciados para garantir a qualidade do software e também reduzir seus custos de manutenção e evolução. Porém, as ferramentas para detecção de TD geralmente fornecem resultados apenas considerando a perspectiva dos arquivos (classes e métodos), o que não é usual durante o gerenciamento de projetos. Neste trabalho é proposta uma técnica para identificar/visualizar DT sob uma nova perspectiva: funcionalidades de software. A técnica proposta adota ferramentas Mining Software Repository (MRS) para identificar as funcionalidades do software e após as dívidas técnicas que afetam essas funcionalidades. Adicionalmente, também propusemos uma abordagem para apoiar tarefas de manutenção guiada pela visualização de TD no nível de feature visando avaliar sua aplicabilidade em projetos reais de software. Os resultados indicam que a abordagem pode ser útil para diminuir os DTs existentes, bem como evitar a introdução de novos DTs."
A survey of software aging and rejuvenation studies,Uma pesquisa sobre estudos de envelhecimento e rejuvenescimento de software,"Cotroneo, Domenico and Natella, Roberto and Pietrantuono, Roberto and Russo, Stefano","Software aging is a phenomenon plaguing many long-running complex software systems, which exhibit performance degradation or an increasing failure rate. Several strategies based on the proactive rejuvenation of the software state have been proposed to counteract software aging and prevent failures. This survey article provides an overview of studies on Software Aging and Rejuvenation (SAR) that have appeared in major journals and conference proceedings, with respect to the statistical approaches that have been used to forecast software aging phenomena and to plan rejuvenation, the kind of systems and aging effects that have been studied, and the techniques that have been proposed to rejuvenate complex software systems. The analysis is useful to identify key results from SAR research, and it is leveraged in this article to highlight trends and open issues.","O envelhecimento do software é um fenômeno que assola muitos sistemas de software complexos de longa execução, que apresentam degradação de desempenho ou uma taxa de falhas crescente. Várias estratégias baseadas no rejuvenescimento proativo do estado do software foram propostas para neutralizar o envelhecimento do software e prevenir falhas. Este artigo de pesquisa fornece uma visão geral dos estudos sobre Envelhecimento e Rejuvenescimento de Software (SAR) que apareceram nos principais periódicos e anais de conferências, com relação às abordagens estatísticas que foram usadas para prever fenômenos de envelhecimento de software e planejar o rejuvenescimento, o tipo de sistemas e efeitos de envelhecimento que foram estudados, e as técnicas que foram propostas para rejuvenescer sistemas de software complexos. A análise é útil para identificar os principais resultados da investigação SAR e é aproveitada neste artigo para destacar tendências e questões em aberto."
Comparison of Machine Learning Algorithms for Detecting Software Aging in SQL Server,Comparação de algoritmos de aprendizado de máquina para detecção de envelhecimento de software no SQL Server,"Nascimento, Maria Gizele and Moura, Rafael Jos\'{e} and Machida, Fumio and Andrade, Ermeson","Software aging is a phenomenon characterized by the progressive degradation of system performance, resulting from the accumulation of internal erros, such as memory leaks and resource exhaustion. Efficient detection of this process is essential to prevent critical failures in production environments. Although several studies use Machine Learning (ML) algorithms to detect software aging, systematic comparison between these algorithms is still limited, especially in terms of their ability to predict resource exhaustion. This paper aims to fill this gap by comparing ML algorithms for detecting software aging, focusing on RAM memory exhaustion as the main indicator. The analysis was conducted using a dataset on RAM memory usage in SQL Server, applying the algorithms K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Random Forest (RF). The performance of the models was evaluated using the metrics Mean Absolute Error (MAE), Root Mean Square Error (RMSE) and coefficient of determination (R2). Based on these indicators, it was possible to identify the most accurate algorithm and predict the time until memory exhaustion.","O envelhecimento de software é um fenômeno caracterizado pela degradação progressiva do desempenho do sistema, resultante do acúmulo de erros internos, como vazamentos de memória e esgotamento de recursos. A detecção eficiente deste processo é essencial para evitar falhas críticas em ambientes de produção. Embora vários estudos utilizem algoritmos de Aprendizado de Máquina (ML) para detectar o envelhecimento de software, a comparação sistemática entre esses algoritmos ainda é limitada, especialmente em termos de sua capacidade de prever o esgotamento de recursos. Este artigo visa preencher essa lacuna comparando algoritmos de ML para detecção de envelhecimento de software, focando no esgotamento da memória RAM como principal indicador. A análise foi realizada utilizando um conjunto de dados sobre uso de memória RAM no SQL Server, aplicando os algoritmos K-Nearest Neighbors (KNN), Support Vector Machine (SVM) e Random Forest (RF). O desempenho dos modelos foi avaliado por meio das métricas Mean Absolute Error (MAE), Root Mean Square Error (RMSE) e coeficiente de determinação (R2). Com base nesses indicadores, foi possível identificar o algoritmo mais preciso e prever o tempo até o esgotamento da memória."